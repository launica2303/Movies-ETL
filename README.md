# Movies-ETL

## Overview

For this analysis an automated pipeline to take in new data will be created. The appropriate transformations, and loading of the data into existing tables will be preformed. Using code refactoring code will be used to create one function that takes in the three files—Wikipedia data, Kaggle metadata, and the MovieLens rating data. Using the ETL process the data will be added to a PostgreSQL database.

## Results:
For this analysis we will be creating:
•	A written ETL Function to Read Three Data Files
•	Extracting and transforming the Wikipedia Data
•	Extracting and transforming the Kaggle data
•	Creating the Movie Database

## Summary:
Using ETL to clean the movie data from Wikipedia JSON, Kaggle and ratings csv files. Merging the data and loading it into PostgreSQL dataset tables for Amazing Prime Hackathon to use for their analysis.
